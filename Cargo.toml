[package]
name = "halldyll_agent"
version = "0.1.0"
edition = "2024"
description = "Cloud-based LLM agent with remote Ollama backend"
default-run = "halldyll"

[dependencies]
# Core
serde = { version = "1", features = ["derive"] }
serde_json = "1"
thiserror = "1.0"

# HTTP client for Ollama
reqwest = { version = "0.12", default-features = false, features = ["blocking", "json", "rustls-tls"] }

# Async runtime
tokio = { version = "1.45", features = ["macros", "rt-multi-thread", "sync"] }

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Web server
axum = "0.8"
tower-http = { version = "0.6", features = ["cors", "trace", "fs"] }

# Launcher (local binary only)
ctrlc = { version = "3.4", features = ["termination"] }
tokio-util = "0.7"

[[bin]]
name = "halldyll"
path = "src/bin/launcher.rs"

[[bin]]
name = "halldyll-server"
path = "src/bin/server.rs"
